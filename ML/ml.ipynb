{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports ##",
   "id": "24027e5b3bb41543"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:55:37.023314Z",
     "start_time": "2025-11-03T15:55:37.021140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "cf30530cb58ee011",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:55:37.180174Z",
     "start_time": "2025-11-03T15:55:37.029439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Loading Dataset\n",
    "DATASET_PATH = \"../Datasets/Covid_Cleaned.csv\"\n",
    "COVID_data = pd.read_csv(DATASET_PATH)"
   ],
   "id": "b5945b38e08262cf",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Batch preperation ##",
   "id": "be9032881ad1932c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:55:37.233389Z",
     "start_time": "2025-11-03T15:55:37.185458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = COVID_data.drop(columns=['CLASIFFICATION_FINAL'])  # features (21)\n",
    "y = COVID_data['CLASIFFICATION_FINAL']                 # target (low / high risk of COVID-19)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42) # 70% train, 30% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) # test -> 15% validation, 15% final test"
   ],
   "id": "207002e130805d48",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:55:37.250136Z",
     "start_time": "2025-11-03T15:55:37.237066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating Pytorch Tensors\n",
    "X_train_tensor = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val.to_numpy(), dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.float32)"
   ],
   "id": "34081b69d43f6c2",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:55:37.256577Z",
     "start_time": "2025-11-03T15:55:37.254329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)"
   ],
   "id": "8e4cc0cfc03a1931",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:55:37.307357Z",
     "start_time": "2025-11-03T15:55:37.261091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ],
   "id": "543440682810fb26",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Training ##",
   "id": "cddba00ce8bc5bf7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:55:37.314740Z",
     "start_time": "2025-11-03T15:55:37.312440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from src.utils import OurModel\n"
   ],
   "id": "1440ca878e6de2c2",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:55:37.321350Z",
     "start_time": "2025-11-03T15:55:37.318721Z"
    }
   },
   "cell_type": "code",
   "source": "ml = OurModel()",
   "id": "624406d7c0c404d6",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:55:37.328396Z",
     "start_time": "2025-11-03T15:55:37.325327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configuration\n",
    "config = nn.Sequential(\n",
    "    nn.Linear(20, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 20),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(20, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 1),\n",
    ")\n",
    "ml.add_configuration(config)"
   ],
   "id": "663c5fc6e8b9b3dc",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:55:37.334973Z",
     "start_time": "2025-11-03T15:55:37.332267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(ml.parameters(), lr=0.001)"
   ],
   "id": "12db45e809e8f897",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:55:37.423887Z",
     "start_time": "2025-11-03T15:55:37.341793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model Training\n",
    "\n",
    "epochs = range(20)\n",
    "for ep in epochs:\n",
    "    ml.train()\n",
    "    sum_loss = 0\n",
    "    for input, true in train_loader:\n",
    "        y_pred = ml(input)\n",
    "        loss = criterion(y_pred, true)\n",
    "        optimizer.zero_grad() # Reseting gradient\n",
    "        loss.backward()\n",
    "        optimizer.step() # updating\n",
    "        sum_loss += loss.item()\n"
   ],
   "id": "af8339cda59510c1",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[116]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28minput\u001B[39m, true \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[32m      8\u001B[39m     y_pred = ml(\u001B[38;5;28minput\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m     loss = \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m     optimizer.zero_grad() \u001B[38;5;66;03m# Reseting gradient\u001B[39;00m\n\u001B[32m     11\u001B[39m     loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\loss.py:1385\u001B[39m, in \u001B[36mCrossEntropyLoss.forward\u001B[39m\u001B[34m(self, input, target)\u001B[39m\n\u001B[32m   1383\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) -> Tensor:\n\u001B[32m   1384\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Runs the forward pass.\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1385\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1386\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1387\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1388\u001B[39m \u001B[43m        \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1389\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1390\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1391\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1392\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\functional.py:3458\u001B[39m, in \u001B[36mcross_entropy\u001B[39m\u001B[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[39m\n\u001B[32m   3456\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   3457\u001B[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001B[32m-> \u001B[39m\u001B[32m3458\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_C\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_nn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   3459\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   3460\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3461\u001B[39m \u001B[43m    \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3462\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3463\u001B[39m \u001B[43m    \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3464\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3465\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: expected scalar type Long but found Float"
     ]
    }
   ],
   "execution_count": 116
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
